#!/usr/bin/env python3

"""
PaStA - Patch Stack Analysis

Copyright (c) OTH Regensburg, 2016-2017

Author:
  Ralf Ramsauer <ralf.ramsauer@oth-regensburg.de>

This work is licensed under the terms of the GNU GPL, version 2.  See
the COPYING file in the top-level directory.
"""

import configparser
import csv
from git import Repo
from multiprocessing import Pool, cpu_count
from subprocess import call
import sys
import os


def save_hashlist(filename, hashlist):
    with open(filename, 'w') as f:
        f.write('\n'.join(hashlist) + '\n')


def get_hashlist(range):
    if range[0] is None:
        range = range[1]
    else:
        range = '%s..%s' % range

    upstream_hashes = repo.git.log('--pretty=format:%H', range)
    upstream_hashes = upstream_hashes.splitlines()
    return upstream_hashes


def get_stack_hashlist(base, stack):
    stack_list = get_hashlist((None, stack))
    base_set = set(get_hashlist((None, base)))

    # Preserve order!
    retval = []
    for stack_hash in stack_list:
        if stack_hash not in base_set:
            retval.append(stack_hash)
    return retval


def _get_stack_hashlist_helper(args):
    patch_version, base, stack = args
    print('Working on %s' % patch_version)
    retval = get_stack_hashlist(base, stack)
    return patch_version, retval


cfg = configparser.ConfigParser()
cfg.read(sys.argv[1:3])
pasta = cfg['PaStA']

stack_hashes_location = pasta.get('STACK_HASHES')
repo_location = pasta.get('REPO')
patch_stack_definition = pasta.get('PATCH_STACK_DEFINITION')
upstream_range = (pasta.get('UPSTREAM_MIN'), pasta.get('UPSTREAM_MAX'))

repo = Repo(repo_location)
os.makedirs(stack_hashes_location, exist_ok=True)

csv.register_dialect('patchstack', delimiter=' ', quoting=csv.QUOTE_NONE)
work_list = []
with open(patch_stack_definition) as f:
    lines = f.readlines()
    lines = filter(lambda row: row != '\n', lines)
    lines = filter(lambda row: row[0] != '#', lines)

    reader = csv.DictReader(lines, dialect='patchstack')
    for row in reader:
        base = row['BaseCommit']
        stack = row['Branch']
        patch_version = row['StackVersion']

        if os.path.isfile(os.path.join(stack_hashes_location, patch_version)):
            print('Stack hashes already exist for %s' % patch_version)
        else:
            work_list.append((patch_version, base, stack))


print('Collecting upstream commit hashes...')
upstream_hashes = get_hashlist(upstream_range)
save_hashlist(os.path.join(stack_hashes_location, 'upstream'), upstream_hashes)

print('Collecting patch stack commit hashes...')
pool = Pool(cpu_count())
results = pool.map(_get_stack_hashlist_helper, work_list)
pool.close()
pool.join()

print('Writing stack hashes...')
for patch_version, stack_hashes in results:
    save_hashlist(os.path.join(stack_hashes_location, patch_version), stack_hashes)
